{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e765901-cf38-4feb-8200-51d55cf883b4",
   "metadata": {},
   "source": [
    "### Se lee el conjunto de datos como dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d77f9b79-90f8-4668-a751-a2ed96fd6b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Musicians to tackle US red tape  Musicians gro...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U2s desire to be number one  U2, who have won ...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rocker Doherty in on-stage fight  Rock singer ...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Snicket tops US box office chart  The film ada...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oceans Twelve raids box office  Oceans Twelve,...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data         labels\n",
       "0  Musicians to tackle US red tape  Musicians gro...  entertainment\n",
       "1  U2s desire to be number one  U2, who have won ...  entertainment\n",
       "2  Rocker Doherty in on-stage fight  Rock singer ...  entertainment\n",
       "3  Snicket tops US box office chart  The film ada...  entertainment\n",
       "4  Oceans Twelve raids box office  Oceans Twelve,...  entertainment"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se lee el conjunto de datos como dataframe\n",
    "import pandas as pd\n",
    "\n",
    "ruta = 'bbc_data.csv'\n",
    "# Leer un archivo CSV (si ya lo tienes subido)\n",
    "df = pd.read_csv(ruta)\n",
    "\n",
    "# Ver las primeras filas\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0060016d-6042-4b0c-9bde-f5195d143b17",
   "metadata": {},
   "source": [
    "### Se realiza un preprocesamiento de las noticias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abf26f91-7dc1-4622-9c2c-b371b88ac215",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Usuario/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Usuario/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Usuario/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Se realiza un preprocesamiento de las noticias\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess(text):\n",
    "    # Min√∫sculas\n",
    "    text = text.lower()\n",
    "    # Quitar signos de puntuaci√≥n\n",
    "    text = re.sub(f\"[{re.escape(string.punctuation)}]\", \"\", text)\n",
    "    # Tokenizar\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    # Quitar stopwords y lematizar\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Aplicar al dataframe\n",
    "df['clean_text'] = df['data'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f3cbcb-a6fb-49e0-8b88-1f9d52a18001",
   "metadata": {},
   "source": [
    "### Entrenamiento de dos Modelos LTSM. El primero solo tiene en cuenta el contexto por un lado, y el segundo tiene en cuenta el contexto por los dos lados, lo que mejora mucho el accuracy.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1eb62590-659c-4c3e-80db-180028c0d5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento de dos Modelos LTSM. El primero solo tiene en cuenta el contexto por un lado, y el segundo tiene en cuenta el contexto por los dos lados, lo que mejora mucho el accuracy.  \n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Par√°metros\n",
    "MAX_WORDS = 5000  # tama√±o del vocabulario\n",
    "MAX_LEN = 200     # longitud m√°xima de cada secuencia\n",
    "\n",
    "# Tokenizar texto\n",
    "tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(df['clean_text'])\n",
    "\n",
    "# Convertir textos a secuencias de enteros\n",
    "sequences = tokenizer.texts_to_sequences(df['clean_text'])\n",
    "\n",
    "# Rellenar secuencias a longitud fija\n",
    "X = pad_sequences(sequences, maxlen=MAX_LEN, padding='post', truncating='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc3266c0-b3cf-487b-9f26-431164377d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Codificar etiquetas a enteros\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(df['labels'])\n",
    "\n",
    "# Convertir a one-hot\n",
    "y = to_categorical(y_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4dfa71e1-a76b-473f-af1d-30535b76517d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e75334a-bdd7-4046-8112-b92c08acf5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 200, 128)          640000    \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, 200, 64)           49408     \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 200, 64)           0         \n",
      "                                                                 \n",
      " lstm_9 (LSTM)               (None, 32)                12416     \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 5)                 165       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 701989 (2.68 MB)\n",
      "Trainable params: 701989 (2.68 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=MAX_WORDS, output_dim=128, input_length=MAX_LEN))\n",
    "model.add(LSTM(64, return_sequences=True))     # Primera capa LSTM (devuelve secuencia)\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(32))                            # Segunda capa LSTM (finaliza secuencia)\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be11c712-1443-483c-ba4e-81b4b489b4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "56/56 [==============================] - 14s 191ms/step - loss: 1.5257 - accuracy: 0.2815 - val_loss: 1.1809 - val_accuracy: 0.4135\n",
      "Epoch 2/30\n",
      "56/56 [==============================] - 10s 180ms/step - loss: 1.2363 - accuracy: 0.4152 - val_loss: 1.2134 - val_accuracy: 0.4067\n",
      "Epoch 3/30\n",
      "56/56 [==============================] - 10s 171ms/step - loss: 1.4253 - accuracy: 0.3444 - val_loss: 1.4260 - val_accuracy: 0.3213\n",
      "Epoch 4/30\n",
      "56/56 [==============================] - 9s 168ms/step - loss: 1.3707 - accuracy: 0.3978 - val_loss: 1.2802 - val_accuracy: 0.3933\n",
      "Epoch 5/30\n",
      "56/56 [==============================] - 9s 167ms/step - loss: 1.2761 - accuracy: 0.4399 - val_loss: 1.2390 - val_accuracy: 0.4584\n",
      "Epoch 6/30\n",
      "56/56 [==============================] - 9s 167ms/step - loss: 1.2256 - accuracy: 0.4826 - val_loss: 1.1106 - val_accuracy: 0.5438\n",
      "Epoch 7/30\n",
      "56/56 [==============================] - 9s 167ms/step - loss: 1.0837 - accuracy: 0.5376 - val_loss: 1.0594 - val_accuracy: 0.5596\n",
      "Epoch 8/30\n",
      "56/56 [==============================] - 9s 167ms/step - loss: 0.9112 - accuracy: 0.6191 - val_loss: 0.9399 - val_accuracy: 0.5888\n",
      "Epoch 9/30\n",
      "56/56 [==============================] - 9s 169ms/step - loss: 0.9828 - accuracy: 0.5584 - val_loss: 0.9483 - val_accuracy: 0.5775\n",
      "Epoch 10/30\n",
      "56/56 [==============================] - 9s 168ms/step - loss: 0.8858 - accuracy: 0.5955 - val_loss: 0.9018 - val_accuracy: 0.6270\n",
      "Epoch 11/30\n",
      "56/56 [==============================] - 9s 167ms/step - loss: 0.8880 - accuracy: 0.6433 - val_loss: 1.1219 - val_accuracy: 0.4764\n",
      "Epoch 12/30\n",
      "56/56 [==============================] - 9s 168ms/step - loss: 0.8877 - accuracy: 0.6163 - val_loss: 0.8582 - val_accuracy: 0.6899\n",
      "Epoch 13/30\n",
      "56/56 [==============================] - 9s 167ms/step - loss: 0.7037 - accuracy: 0.7090 - val_loss: 0.7352 - val_accuracy: 0.7034\n",
      "Epoch 14/30\n",
      "56/56 [==============================] - 9s 167ms/step - loss: 0.5810 - accuracy: 0.7522 - val_loss: 0.5921 - val_accuracy: 0.7708\n",
      "Epoch 15/30\n",
      "56/56 [==============================] - 9s 170ms/step - loss: 0.4663 - accuracy: 0.8129 - val_loss: 0.6285 - val_accuracy: 0.7955\n",
      "Epoch 16/30\n",
      "56/56 [==============================] - 9s 169ms/step - loss: 0.4777 - accuracy: 0.8157 - val_loss: 0.5454 - val_accuracy: 0.8067\n",
      "Epoch 17/30\n",
      "56/56 [==============================] - 9s 167ms/step - loss: 0.4933 - accuracy: 0.8129 - val_loss: 0.5433 - val_accuracy: 0.7933\n",
      "Epoch 18/30\n",
      "56/56 [==============================] - 9s 169ms/step - loss: 0.9727 - accuracy: 0.6708 - val_loss: 1.1208 - val_accuracy: 0.5303\n",
      "Epoch 19/30\n",
      "56/56 [==============================] - 9s 167ms/step - loss: 1.6531 - accuracy: 0.4090 - val_loss: 1.8638 - val_accuracy: 0.3371\n",
      "Epoch 20/30\n",
      "56/56 [==============================] - 9s 166ms/step - loss: 1.6083 - accuracy: 0.3185 - val_loss: 1.4259 - val_accuracy: 0.3393\n",
      "Epoch 21/30\n",
      "56/56 [==============================] - 9s 168ms/step - loss: 1.3603 - accuracy: 0.4157 - val_loss: 1.2466 - val_accuracy: 0.4787\n",
      "Epoch 22/30\n",
      "56/56 [==============================] - 9s 166ms/step - loss: 1.1248 - accuracy: 0.5438 - val_loss: 1.0228 - val_accuracy: 0.5663\n",
      "Epoch 23/30\n",
      "56/56 [==============================] - 9s 167ms/step - loss: 0.9750 - accuracy: 0.5955 - val_loss: 0.8707 - val_accuracy: 0.6629\n",
      "Epoch 24/30\n",
      "56/56 [==============================] - 9s 168ms/step - loss: 0.8143 - accuracy: 0.7090 - val_loss: 0.8004 - val_accuracy: 0.7775\n",
      "Epoch 25/30\n",
      "56/56 [==============================] - 9s 167ms/step - loss: 0.7356 - accuracy: 0.7685 - val_loss: 0.7207 - val_accuracy: 0.8157\n",
      "Epoch 26/30\n",
      "56/56 [==============================] - 9s 170ms/step - loss: 0.6359 - accuracy: 0.8219 - val_loss: 0.6504 - val_accuracy: 0.8292\n",
      "Epoch 27/30\n",
      "56/56 [==============================] - 10s 180ms/step - loss: 0.5496 - accuracy: 0.8562 - val_loss: 0.6087 - val_accuracy: 0.8337\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "    ModelCheckpoint('best_model_1.h5', save_best_only=True)  # ‚Üê CAMBIO a .h5\n",
    "]\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    callbacks = callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fbd99a76-fecb-47db-938f-5854dbeeedf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, 200, 128)          640000    \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 200, 128)          98816     \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 200, 128)          0         \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirecti  (None, 64)                41216     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 780357 (2.98 MB)\n",
      "Trainable params: 780357 (2.98 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "\n",
    "\n",
    "model2 = Sequential()\n",
    "\n",
    "# Capa de embeddings\n",
    "model2.add(Embedding(input_dim=MAX_WORDS, output_dim=128, input_length=MAX_LEN))\n",
    "\n",
    "# Primera capa Bidirectional LSTM (devuelve secuencias para la siguiente LSTM)\n",
    "model2.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "model2.add(Dropout(0.3))\n",
    "\n",
    "# Segunda capa Bidirectional LSTM (no necesita devolver secuencia)\n",
    "model2.add(Bidirectional(LSTM(32)))\n",
    "model2.add(Dropout(0.3))\n",
    "\n",
    "# Capa de salida (tantas neuronas como clases)\n",
    "model2.add(Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "# Compilar el modelo\n",
    "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Resumen del modelo\n",
    "model2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bdeeed50-8d51-44b0-9213-cfece72c2580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "56/56 [==============================] - 29s 402ms/step - loss: 1.3270 - accuracy: 0.4618 - val_loss: 0.7548 - val_accuracy: 0.6921\n",
      "Epoch 2/15\n",
      "56/56 [==============================] - 19s 337ms/step - loss: 0.4600 - accuracy: 0.8865 - val_loss: 0.2757 - val_accuracy: 0.9506\n",
      "Epoch 3/15\n",
      "56/56 [==============================] - 17s 312ms/step - loss: 0.2014 - accuracy: 0.9590 - val_loss: 0.1971 - val_accuracy: 0.9596\n",
      "Epoch 4/15\n",
      "56/56 [==============================] - 17s 309ms/step - loss: 0.1028 - accuracy: 0.9848 - val_loss: 0.1326 - val_accuracy: 0.9640\n",
      "Epoch 5/15\n",
      "56/56 [==============================] - 17s 300ms/step - loss: 0.0883 - accuracy: 0.9736 - val_loss: 0.1411 - val_accuracy: 0.9618\n",
      "Epoch 6/15\n",
      "56/56 [==============================] - 16s 288ms/step - loss: 0.0545 - accuracy: 0.9854 - val_loss: 0.1225 - val_accuracy: 0.9640\n",
      "Epoch 7/15\n",
      "56/56 [==============================] - 16s 284ms/step - loss: 0.0229 - accuracy: 0.9972 - val_loss: 0.1238 - val_accuracy: 0.9685\n",
      "Epoch 8/15\n",
      "56/56 [==============================] - 16s 284ms/step - loss: 0.0159 - accuracy: 0.9983 - val_loss: 0.1585 - val_accuracy: 0.9663\n",
      "Epoch 9/15\n",
      "56/56 [==============================] - 16s 284ms/step - loss: 0.0105 - accuracy: 0.9989 - val_loss: 0.1868 - val_accuracy: 0.9618\n",
      "Epoch 10/15\n",
      "56/56 [==============================] - 16s 285ms/step - loss: 0.0077 - accuracy: 0.9989 - val_loss: 0.1372 - val_accuracy: 0.9730\n",
      "Epoch 11/15\n",
      "56/56 [==============================] - 16s 283ms/step - loss: 0.0232 - accuracy: 0.9944 - val_loss: 0.1480 - val_accuracy: 0.9708\n",
      "Epoch 12/15\n",
      "56/56 [==============================] - 16s 285ms/step - loss: 0.0224 - accuracy: 0.9944 - val_loss: 0.1022 - val_accuracy: 0.9730\n",
      "Epoch 13/15\n",
      "56/56 [==============================] - 16s 288ms/step - loss: 0.0099 - accuracy: 0.9978 - val_loss: 0.0872 - val_accuracy: 0.9730\n",
      "Epoch 14/15\n",
      "56/56 [==============================] - 16s 284ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0818 - val_accuracy: 0.9798\n",
      "Epoch 15/15\n",
      "56/56 [==============================] - 16s 290ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0817 - val_accuracy: 0.9798\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "callbacks2 = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "    ModelCheckpoint('best_model_2.h5', save_best_only=True)  # ‚Üê CAMBIO a .h5\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "history = model2.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=15,\n",
    "    batch_size=32,\n",
    "    callbacks = callbacks2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2403d087-4aae-4097-a693-2bf2c0049e7f",
   "metadata": {},
   "source": [
    "### Visualizaci√≥n de una predicci√≥n del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d26efaf-9293-4cad-8783-5a116f80bd83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 122ms/step\n",
      "üì∞ Texto original:\n",
      "\n",
      "Actress Roberts takes spider role  Actress Julia Roberts will play the part of a spider in a new film version of childrens classic Charlottes Web.  She will voice Charlotte, who teams up with a girl to save their friend Wilbur the pig, in the story by EB White. The film - a mix of live action and animation - will be Roberts first project since the birth of her twins, Hazel and Phinnaeus, two months ago. Oprah Winfrey will voice a goose, John Cleese will voice a sheep and Steve Buscemi a rat in the 2006 film.  Ten-year-old Dakota Fanning will play Fern, the girl at the centre of the story, in the film to be directed by 13 Going on 30 film-maker Gary Winick. Filming is due to begin in Melbourne, Australia, later this month. Charlottes Web has sold 45 million copies since it was published in 1952. An animated version was made in 1973 but this will be the first live action film. The actor who will voice Wilbur the pig has yet to be revealed. \"\n",
      "\n",
      "‚úÖ Clase real: entretenimiento\n",
      "ü§ñ Clase predicha: entretenimiento\n"
     ]
    }
   ],
   "source": [
    "### Visualizaci√≥n de una predicci√≥n del conjunto de datos\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Lista de nombres de las clases (ajusta seg√∫n tu problema)\n",
    "clases = [\"entretenimiento\", \"deportes\", \"negocios\", \"tecnolog√≠a\", \"pol√≠tica\"]\n",
    "\n",
    "# √çndice de la noticia a predecir\n",
    "i = 10  # Cambia este n√∫mero para ver otras noticias\n",
    "\n",
    "# Extraer datos\n",
    "noticia_elegida = X_test[i]\n",
    "real = y_test[i]\n",
    "texto_original = df[\"data\"].iloc[i] if \"data\" in df.columns else \"Texto no disponible\"\n",
    "\n",
    "# A√±adir dimensi√≥n para el modelo\n",
    "noticia_input = np.expand_dims(noticia_elegida, axis=0)\n",
    "\n",
    "# Hacer predicci√≥n\n",
    "pred = model2.predict(noticia_input)\n",
    "\n",
    "# Interpretar predicci√≥n\n",
    "if pred.shape[1] == 1:\n",
    "    pred_clase = 1 if pred[0][0] > 0.5 else 0\n",
    "    real_clase_idx = int(real)\n",
    "else:\n",
    "    pred_clase = np.argmax(pred)\n",
    "    real_clase_idx = np.argmax(real)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"üì∞ Texto original:\\n\")\n",
    "print(texto_original.strip())\n",
    "\n",
    "print(f\"\\n‚úÖ Clase real: {clases[real_clase_idx]}\")\n",
    "print(f\"ü§ñ Clase predicha: {clases[pred_clase]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a6c3fd-6eca-4dc1-b70a-d30dbe790fe8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
